{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import trimesh\n",
    "import meshplot as mp\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = './meshes/'\n",
    "\n",
    "mesh_fp = RES + 'cow_manifold2.obj'\n",
    "assert os.path.exists(mesh_fp), 'cannot found:'+mesh_fp \n",
    "cow = trimesh.load_mesh(mesh_fp) \n",
    "\n",
    "mesh_fp = RES + 'human.obj'\n",
    "assert os.path.exists(mesh_fp), 'cannot found:'+mesh_fp \n",
    "human = trimesh.load_mesh(mesh_fp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace-Beltrami Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cotangent_Laplce_Matrix(mesh: trimesh.base.Trimesh):\n",
    "    \n",
    "    '''\n",
    "        Cotangent Laplace Beltrami \n",
    "    '''\n",
    "\n",
    "    vertices = mesh.vertices\n",
    "\n",
    "    faces = mesh.faces\n",
    "    angles = mesh.face_angles\n",
    "    areas = mesh.area_faces\n",
    "\n",
    "    A = np.zeros(len(vertices))\n",
    "    for i in range(len(faces)):\n",
    "        face = faces[i]\n",
    "        area = areas[i]\n",
    "        A[face] += area / 3\n",
    "\n",
    "    L = np.zeros(shape=(len(vertices), len(vertices)))\n",
    "    for i in range(len(faces)):\n",
    "        face = faces[i]\n",
    "        angle = angles[i]\n",
    "\n",
    "        v0, v1, v2 = face\n",
    "        for j, (m, n) in enumerate([(v1, v2), (v0, v2), (v0, v1)]):\n",
    "            cot = (1 / np.tan(angle[j])) * (1 / (A[m] + A[n]))\n",
    "            L[m, n] += cot\n",
    "            L[n, m] += cot\n",
    "            L[n, n] -= cot\n",
    "            L[m, m] -= cot\n",
    "\n",
    "    return sp.csr_matrix(L)\n",
    "\n",
    "\n",
    "def Mesh_Laplace_Matrix(mesh : trimesh.Trimesh):\n",
    "    '''\n",
    "        Mesh Laplace Matrix \n",
    "    '''\n",
    "\n",
    "    vertices = mesh.vertices\n",
    "    edges = mesh.edges_unique\n",
    "    edge_length = mesh.edges_unique_length\n",
    "\n",
    "    h = np.mean(edge_length)\n",
    "    f = 1.0 / (4 * np.pi * h * h)\n",
    "    w = f * np.exp(-edge_length**2/(4.0*h))\n",
    "\n",
    "    L = np.zeros(shape=(len(vertices), len(vertices)))\n",
    "    for idx, (i, j) in enumerate(edges):\n",
    "        L[i, i] += w[idx]\n",
    "        L[j, j] += w[idx]\n",
    "        L[i, j] -= w[idx]\n",
    "        L[j, i] -= w[idx]\n",
    "\n",
    "    return sp.csr_matrix(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Boundary_Vertices(mesh):\n",
    "    '''\n",
    "        Handle Boundary cases\n",
    "    '''\n",
    "    edge_count = {}\n",
    "    \n",
    "    for face in mesh.faces:\n",
    "        edges = [(min(face[i], face[j]), max(face[i], face[j])) for i, j in [(0, 1), (1, 2), (2, 0)]]\n",
    "        for edge in edges:\n",
    "            if edge in edge_count:\n",
    "                edge_count[edge] += 1\n",
    "            else:\n",
    "                edge_count[edge] = 1\n",
    "    \n",
    "    # Find vertices that are part of boundary edges\n",
    "    boundary_vertices_set = set()\n",
    "    for edge, count in edge_count.items():\n",
    "        if count == 1:  # Edge is a boundary edge\n",
    "            boundary_vertices_set.update(edge)\n",
    "    \n",
    "    boundary_vertices = list(boundary_vertices_set)\n",
    "    \n",
    "    return boundary_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heat(eigval, eigvec, t, ver_idx, mesh, heatValue=100.0):\n",
    "    '''\n",
    "        Use heat operator to get heat\n",
    "    '''\n",
    "\n",
    "    I = np.zeros(eigvec.shape[0])\n",
    "    I[ver_idx] = heatValue\n",
    "    coeffs = (I @ eigvec) * np.exp(-eigval * t)\n",
    "    heat = eigvec @ coeffs.T\n",
    "\n",
    "    boundary_vertices = Find_Boundary_Vertices(mesh)\n",
    "    if len(boundary_vertices) !=0:\n",
    "    # # Set the function value to 0 at each boundary vertex\n",
    "        for vertex in boundary_vertices:\n",
    "            heat[vertex] = 0\n",
    "            \n",
    "    return heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heat_Operator(mesh, k, heat_value, vertex_index, t_index, vertex_labels = [\"Front Right Foot\", \"Front Left Foot\", \"Back Right Foot\", \"Back Left Foot\", \"Head\"], method = Cotangent_Laplce_Matrix, plot_graph=True, plot_mesh=True): \n",
    "    '''\n",
    "        Use heat operator to plot graph heat difference as times passes\n",
    "    '''\n",
    "\n",
    "    L = method(mesh)\n",
    "    e_values, e_vectors = sp.linalg.eigs(L, k=k, which='SM')\n",
    "\n",
    "    num_interval = 100\n",
    "\n",
    "    T = np.linspace(4 * np.log(10) / e_values[-1], 4 * np.log(10) / e_values[1], num_interval, endpoint=True)\n",
    "    heat = np.zeros(shape=(num_interval, len(vertex_index)))\n",
    "    scaled_heat = np.zeros_like(heat)\n",
    "\n",
    "    for i in range(num_interval):\n",
    "        h = get_heat(e_values, e_vectors, T[i], vertex_index, mesh, heatValue=heat_value)\n",
    "        for j in range(len(vertex_index)):\n",
    "            heat[i][j] = h[vertex_index[j]].real.item()\n",
    "    \n",
    "    for i in range(num_interval):\n",
    "        integral_approx = np.sum(heat[i, :])\n",
    "        scaled_heat[i, :] = heat[i, :] / integral_approx if integral_approx != 0 else heat[i, :]\n",
    "\n",
    "    if plot_mesh:\n",
    "        h = get_heat(e_values, e_vectors, t_index, vertex_index, mesh, heatValue=heat_value)\n",
    "        print(\"Heat Distribution at time {0} with eigenfunctions of {1}\".format(t_index, k))\n",
    "        mp.plot(mesh.vertices, mesh.faces, h.real)\n",
    "\n",
    "    if plot_graph:\n",
    "        for i in range(len(vertex_index)):\n",
    "            plt.plot(np.log10(T), scaled_heat[:,i], label = vertex_labels[i])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return scaled_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cow\n",
    "cow_heat = Heat_Operator(mesh=cow, k=300, heat_value=100, t_index=0.5, vertex_index=[2483, 2406, 2522, 2445, 829], method=Mesh_Laplace_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human\n",
    "human_heat = Heat_Operator(mesh=human, k=300, heat_value=100, t_index=3, vertex_index=[4316, 4504, 66, 53, 9525], vertex_labels = [\"Right Hand\", \"Left Hand\", \"Right Foot\", \"Left Foot\", \"Head\"], method=Mesh_Laplace_Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Kernel Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hks(eigenval, eigenvec, t):\n",
    "    '''\n",
    "        Use heat kernel signiture to get heat\n",
    "    '''\n",
    "    hks = (eigenvec**2) * np.exp(eigenval * t * -1)\n",
    "    return np.sum(hks, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heat_Kernel_Signature(mesh, vertex_index, k=300, t_index=0.5, vertex_labels = [\"Front Right Foot\", \"Front Left Foot\", \"Back Right Foot\", \"Back Left Foot\", \"Head\"], method = Cotangent_Laplce_Matrix, plot_graph=True, plot_mesh=True):\n",
    "    '''\n",
    "        Use HKS to plot graph heat difference as times passes\n",
    "    '''\n",
    "\n",
    "    L = method(mesh)\n",
    "    e_values, e_vectors = sp.linalg.eigs(L, k=k, which='SM')\n",
    "\n",
    "    num_interval = 100\n",
    "\n",
    "    T = np.linspace(4 * np.log(10) / e_values[-1], 4 * np.log(10) / e_values[1], num_interval, endpoint=True)\n",
    "    heat = np.zeros(shape=(num_interval, len(vertex_index)))\n",
    "    scaled_heat = np.zeros_like(heat)\n",
    "\n",
    "    for i in range(num_interval):\n",
    "        h = get_hks(e_values, e_vectors, T[i])\n",
    "        heat[i] = h[vertex_index].real\n",
    "\n",
    "    for i in range(num_interval):\n",
    "        integral_approx = np.sum(heat[i, :])\n",
    "        scaled_heat[i, :] = heat[i, :] / integral_approx if integral_approx != 0 else heat[i, :]\n",
    "\n",
    "    if plot_mesh:\n",
    "        h = get_hks(e_values, e_vectors, t_index)\n",
    "        print(\"Heat Distribution at time {0} with eigenfunctions of {1}\".format(t_index, k))\n",
    "        mp.plot(mesh.vertices, mesh.faces, h.real)\n",
    "\n",
    "    if plot_graph:\n",
    "        for i in range(len(vertex_index)):\n",
    "            plt.plot(np.log10(T), scaled_heat[:,i], label = vertex_labels[i])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return scaled_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cow\n",
    "cow_hks = Heat_Kernel_Signature(cow, t_index=0.5, vertex_index=[2483, 2406, 2522, 2445, 829], method=Mesh_Laplace_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human\n",
    "human_hks = Heat_Kernel_Signature(human, t_index=3, vertex_index=[4316, 4504, 66, 53, 9525], vertex_labels = [\"Right Hand\", \"Left Hand\", \"Right Foot\", \"Left Foot\", \"Head\"], method=Mesh_Laplace_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heat_Kernel_Signature_Dis(mesh, t, vertex_index, method=Cotangent_Laplce_Matrix):\n",
    "    '''\n",
    "        HKS scaled difference\n",
    "    '''\n",
    "\n",
    "    L = method(mesh)\n",
    "    e_values, e_vectors = sp.linalg.eigs(L, k=300, which='SM')\n",
    "\n",
    "    vertices = mesh.vertices\n",
    "    num_interval = 100\n",
    "    \n",
    "    T = np.linspace(t[0], t[1], num_interval, endpoint=True)\n",
    "    heat = np.zeros(shape=(num_interval, len(vertices)))\n",
    "    delta_log_t = np.diff(T, prepend=T[0]) \n",
    "    \n",
    "    diff_set = np.zeros(len(vertices))\n",
    "\n",
    "    for i in range(num_interval):\n",
    "        h = get_hks(e_values, e_vectors, T[i])\n",
    "        for j in range(len(vertices)):\n",
    "            heat[i][j] = h[j].real.item()\n",
    "        normalise_factor = np.sum(np.float64(h.real))\n",
    "        heat[i] /= normalise_factor\n",
    "\n",
    "    for j in range(len(vertices)):\n",
    "        if j!=vertex_index:\n",
    "            bong = (heat[:, vertex_index]-heat[:, j])** 2\n",
    "            diff = np.sqrt(np.sum(bong * delta_log_t, axis =0))\n",
    "            diff_set[j] = diff    \n",
    "\n",
    "    mp.plot(mesh.vertices, mesh.faces, diff_set)\n",
    "\n",
    "    return diff_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cow\n",
    "cow_diff = Heat_Kernel_Signature_Dis(cow, t=[1,2], vertex_index=2483, method = Mesh_Laplace_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human\n",
    "human_diff = Heat_Kernel_Signature_Dis(human, t=[0.01, 1000000], vertex_index=4316, method = Mesh_Laplace_Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Importing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = './SHREC15/train'\n",
    "\n",
    "keys = [\"santa\", \"horse\", \"dog\", \"bird\", \"laptop\", \"female\", \"female\", \"male\", \"child\", \"male\"]\n",
    "training_set = {}\n",
    "for key in keys:\n",
    "    training_set[key] = []\n",
    "\n",
    "n = 10    \n",
    "for id in range(len(os.listdir(RES))):\n",
    "    class_name = keys[id // n]\n",
    "    if class_name == \"child\":\n",
    "        continue\n",
    "    f = str(id) + \".obj\"\n",
    "    \n",
    "    training_set[class_name].append(trimesh.load_mesh(os.path.join(RES, f))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BagOfFeature(mesh, num_clusters, alpha, t0, k=300, method=Cotangent_Laplce_Matrix):\n",
    "\n",
    "    '''\n",
    "        Return Bag of Featrues of mesh\n",
    "    '''\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    from scipy.spatial.distance import pdist\n",
    "\n",
    "    L = method(mesh)\n",
    "    e_values, e_vectors = sp.linalg.eigs(L, k=k, which='SM')\n",
    "\n",
    "    vertices = mesh.vertices\n",
    "    num_interval = 10\n",
    "    \n",
    "    # Time Interval\n",
    "    T = np.array([t0 * alpha**i for i in range(num_interval)])\n",
    "    heat = np.zeros(shape=(num_interval, len(vertices)))\n",
    "\n",
    "    # Heat Feature Description\n",
    "    for i in range(num_interval):\n",
    "        h = get_hks(e_values, e_vectors, T[i])\n",
    "        heat[i,:] = h.real\n",
    "\n",
    "        heat[i,:] /= np.linalg.norm(heat[i,:])\n",
    "    heat = heat.T\n",
    "\n",
    "    #Kmean\n",
    "    kmeans = KMeans(n_clusters=num_clusters, n_init='auto')\n",
    "    kmeans.fit(heat)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    \n",
    "    # Calculate pairwise distances between centers and find the median\n",
    "    distances = pdist(centers)\n",
    "    sigma = np.median(distances)\n",
    "\n",
    "    # Calculate the Bag of Features histogram\n",
    "    f_distribution = np.zeros((len(vertices), num_clusters))\n",
    "    for i in range(len(vertices)):\n",
    "        for j in range(num_clusters):\n",
    "            f_distribution[i][j] = np.exp(-np.linalg.norm(heat[i, :] - centers[j]) / (2 * sigma**2))\n",
    "            \n",
    "        constraint = np.sum(f_distribution[i, :])\n",
    "        if constraint != 0:\n",
    "            f_distribution[i, :] /= constraint\n",
    "        \n",
    "    BoF = np.sum(f_distribution, axis=0)\n",
    "    \n",
    "    return BoF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoF_Data_Class(dataset, k, alpha, t0):\n",
    "    '''\n",
    "       Compute Bag of features of dataset at once\n",
    "    '''\n",
    "\n",
    "    keys = dataset.keys()\n",
    "    class_names = list(keys)\n",
    "\n",
    "    y = []\n",
    "    x = []\n",
    "    for i, name in enumerate(class_names):\n",
    "\n",
    "        meshes = dataset[name]\n",
    "\n",
    "        for m in range(len(meshes)):\n",
    "            BoF = BagOfFeature(meshes[m], k, alpha, t0, method=Mesh_Laplace_Matrix)\n",
    "            if len(BoF) == k:\n",
    "                x.append(BoF)\n",
    "                y.append(i)\n",
    "                print(\"Finished! {} - {}\".format(name, m))\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = BoF_Data_Class(training_set, k=10, alpha=1.32, t0=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Bag of features and lables\n",
    "np.save('./reference_BoF/BoF.npy', data)\n",
    "np.save('./reference_BoF/labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bag of features and lables\n",
    "data = np.load('./reference_BoF/BoF.npy')\n",
    "labels = np.load('./reference_BoF/labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoF_KNN(train, label, test):\n",
    "\n",
    "    '''\n",
    "        Perform KNN\n",
    "    '''\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    # Create KNN classifier with n_neighbors and p=1 for L1 distance\n",
    "    knn = KNeighborsClassifier(n_neighbors=11, p=1, metric='minkowski')\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(train, label)\n",
    "\n",
    "    probabilities = knn.predict_proba(test)\n",
    "\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "data = np.array(data)  \n",
    "labels = np.array(labels)  \n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=101)\n",
    "\n",
    "for train_index, test_index in sss.split(data, labels):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "probabilities = BoF_KNN(X_train, y_train, X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PR Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PR_curve(probability, gt, class_names=None):\n",
    "    '''\n",
    "        Plot PR curve\n",
    "    '''\n",
    "\n",
    "    from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "    n_classes = len(np.unique(gt))\n",
    "\n",
    "    Y_test = []\n",
    "    for i in range(len(gt)):\n",
    "        label = np.zeros(n_classes)\n",
    "        label[gt[i]] = 1\n",
    "        Y_test.append(label)\n",
    "    Y_test = np.array(Y_test)\n",
    "\n",
    "    probability = np.array(probability)\n",
    "\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i], probability[:, i])\n",
    "        average_precision[i] = average_precision_score(Y_test[:, i], probability[:, i])\n",
    "\n",
    "        if class_names:\n",
    "            plt.step(recall[i], precision[i], where='post', label=class_names[i])\n",
    "        else:\n",
    "            plt.step(recall[i], precision[i], where='post', label='Class {0}'.format(i))\n",
    "        \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "    return precision, recall, average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _ = PR_curve(probabilities, y_test, class_names=[\"santa\", \"horse\", \"dog\", \"bird\", \"laptop\", \"female\", \"male\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDS Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MDS_Graph(meshes, vertex_index, method=Cotangent_Laplce_Matrix):\n",
    "\n",
    "    '''\n",
    "        Plot MDS Graph\n",
    "    '''\n",
    "    \n",
    "    from sklearn.manifold import MDS\n",
    "\n",
    "    data = []\n",
    "    for i, mesh in enumerate(meshes):\n",
    "        heat = Heat_Kernel_Signature(mesh, vertex_index, method=method, plot_mesh=False, plot_graph=False)\n",
    "        if i == 0:\n",
    "            data = heat\n",
    "        else:\n",
    "            data = np.hstack((data, heat))\n",
    "\n",
    "    # Normalize data\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i, :] /= np.sum(data[i, :])\n",
    "\n",
    "    mds = MDS(n_components=2)\n",
    "    embedding = mds.fit_transform(data.T)\n",
    "\n",
    "    # Generate colors and labels\n",
    "    colors = [np.random.random((1, 3)) for _ in range(len(meshes))]\n",
    "    labels = [f'human{i+1}' for i in range(len(meshes))]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Plot each mesh with its respective color and label\n",
    "    for i, color in enumerate(colors):\n",
    "        indices = range(i * len(vertex_index), (i + 1) * len(vertex_index))\n",
    "        plt.scatter(embedding[indices, 0], embedding[indices, 1], c=color, label=labels[i])\n",
    "\n",
    "    vertex_labels = [\"Right Hand\", \"Left Hand\", \"Right Foot\", \"Left Foot\", \"Head\"]\n",
    "    for i, text in enumerate(vertex_labels):\n",
    "        plt.annotate(text, (embedding[i, 0], embedding[i,1]))\n",
    "\n",
    "    plt.xlabel('MDS Dimension 1')\n",
    "    plt.ylabel('MDS Dimension 2')\n",
    "    plt.title('MDS Plot of Time vs. Vertex')\n",
    "    plt.grid(True)\n",
    "    plt.legend()  \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human1 = trimesh.load_mesh('./meshes/human1.obj') \n",
    "human2 = trimesh.load_mesh('./meshes/human2.obj') \n",
    "human3 = trimesh.load_mesh('./meshes/human3.obj') \n",
    "\n",
    "meshes = [human1, human2, human3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDS_Graph(meshes, vertex_index=[4316, 4504, 66, 53, 9525], method = Mesh_Laplace_Matrix)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02c1a2e1b446f24283db379533f0f3f876a6350ec40172d1fba7044e059cd85c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('koreait')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
